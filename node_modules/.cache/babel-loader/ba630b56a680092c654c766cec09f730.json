{"ast":null,"code":"import * as tf from \"@tensorflow/tfjs\";\nimport { renderBoxes } from \"./renderBox\";\nimport labels from \"./labels.json\";\nconst numClass = labels.length;\n\n/**\n * Preprocess image / frame before forwarded into the model\n * @param {HTMLVideoElement|HTMLImageElement} source\n * @param {Number} modelWidth\n * @param {Number} modelHeight\n * @returns input tensor, xRatio and yRatio\n */\nconst preprocess = (source, modelWidth, modelHeight) => {\n  let xRatio, yRatio; // ratios for boxes\n\n  const input = tf.tidy(() => {\n    const img = tf.browser.fromPixels(source);\n\n    // padding image to square => [n, m] to [n, n], n > m\n    const [h, w] = img.shape.slice(0, 2); // get source width and height\n    const maxSize = Math.max(w, h); // get max size\n    const imgPadded = img.pad([[0, maxSize - h],\n    // padding y [bottom only]\n    [0, maxSize - w],\n    // padding x [right only]\n    [0, 0]]);\n    xRatio = maxSize / w; // update xRatio\n    yRatio = maxSize / h; // update yRatio\n\n    return tf.image.resizeBilinear(imgPadded, [modelWidth, modelHeight]) // resize frame\n    .div(255.0) // normalize\n    .expandDims(0); // add batch\n  });\n\n  return [input, xRatio, yRatio];\n};\n\n/**\n * Function run inference and do detection from source.\n * @param {HTMLImageElement|HTMLVideoElement} source\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\n * @param {HTMLCanvasElement} canvasRef canvas reference\n * @param {VoidFunction} callback function to run after detection process\n */\nexport const detect = async (source, model, canvasRef, callback = () => {}) => {\n  const [modelWidth, modelHeight] = model.inputShape.slice(1, 3); // get model width and height\n\n  tf.engine().startScope(); // start scoping tf engine\n  const [input, xRatio, yRatio] = preprocess(source, modelWidth, modelHeight); // preprocess image\n\n  const res = model.net.execute(input); // inference model\n  const transRes = res.transpose([0, 2, 1]); // transpose result [b, det, n] => [b, n, det]\n  const boxes = tf.tidy(() => {\n    const w = transRes.slice([0, 0, 2], [-1, -1, 1]); // get width\n    const h = transRes.slice([0, 0, 3], [-1, -1, 1]); // get height\n    const x1 = tf.sub(transRes.slice([0, 0, 0], [-1, -1, 1]), tf.div(w, 2)); // x1\n    const y1 = tf.sub(transRes.slice([0, 0, 1], [-1, -1, 1]), tf.div(h, 2)); // y1\n    return tf.concat([y1, x1, tf.add(y1, h),\n    //y2\n    tf.add(x1, w) //x2\n    ], 2).squeeze();\n  }); // process boxes [y1, x1, y2, x2]\n\n  const [scores, classes] = tf.tidy(() => {\n    // class scores\n    const rawScores = transRes.slice([0, 0, 4], [-1, -1, numClass]).squeeze(0); // #6 only squeeze axis 0 to handle only 1 class models\n    return [rawScores.max(1), rawScores.argMax(1)];\n  }); // get max scores and classes index\n\n  const nms = await tf.image.nonMaxSuppressionAsync(boxes, scores, 500, 0.45, 0.2); // NMS to filter boxes\n\n  const boxes_data = boxes.gather(nms, 0).dataSync(); // indexing boxes by nms index\n  const scores_data = scores.gather(nms, 0).dataSync(); // indexing scores by nms index\n  const classes_data = classes.gather(nms, 0).dataSync(); // indexing classes by nms index\n\n  renderBoxes(canvasRef, boxes_data, scores_data, classes_data, [xRatio, yRatio]); // render boxes\n  tf.dispose([res, transRes, boxes, scores, classes, nms]); // clear memory\n\n  callback();\n  tf.engine().endScope(); // end of scoping\n};\n\n/**\n * Function to detect video from every source.\n * @param {HTMLVideoElement} vidSource video source\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\n * @param {HTMLCanvasElement} canvasRef canvas reference\n */\nexport const detectVideo = (vidSource, model, canvasRef) => {\n  /**\n   * Function to detect every frame from video\n   */\n  const detectFrame = async () => {\n    if (vidSource.videoWidth === 0 && vidSource.srcObject === null) {\n      const ctx = canvasRef.getContext(\"2d\");\n      ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height); // clean canvas\n      return; // handle if source is closed\n    }\n\n    detect(vidSource, model, canvasRef, () => {\n      requestAnimationFrame(detectFrame); // get another frame\n    });\n  };\n\n  detectFrame(); // initialize to detect every frame\n};","map":{"version":3,"names":["tf","renderBoxes","labels","numClass","length","preprocess","source","modelWidth","modelHeight","xRatio","yRatio","input","tidy","img","browser","fromPixels","h","w","shape","slice","maxSize","Math","max","imgPadded","pad","image","resizeBilinear","div","expandDims","detect","model","canvasRef","callback","inputShape","engine","startScope","res","net","execute","transRes","transpose","boxes","x1","sub","y1","concat","add","squeeze","scores","classes","rawScores","argMax","nms","nonMaxSuppressionAsync","boxes_data","gather","dataSync","scores_data","classes_data","dispose","endScope","detectVideo","vidSource","detectFrame","videoWidth","srcObject","ctx","getContext","clearRect","canvas","width","height","requestAnimationFrame"],"sources":["C:/Users/flori/Documents/PythonProjekt/FaceMaskDetection/yolov8n_facemask-tfjs/src/utils/detect.js"],"sourcesContent":["import * as tf from \"@tensorflow/tfjs\";\nimport { renderBoxes } from \"./renderBox\";\nimport labels from \"./labels.json\";\n\nconst numClass = labels.length;\n\n/**\n * Preprocess image / frame before forwarded into the model\n * @param {HTMLVideoElement|HTMLImageElement} source\n * @param {Number} modelWidth\n * @param {Number} modelHeight\n * @returns input tensor, xRatio and yRatio\n */\nconst preprocess = (source, modelWidth, modelHeight) => {\n  let xRatio, yRatio; // ratios for boxes\n\n  const input = tf.tidy(() => {\n    const img = tf.browser.fromPixels(source);\n\n    // padding image to square => [n, m] to [n, n], n > m\n    const [h, w] = img.shape.slice(0, 2); // get source width and height\n    const maxSize = Math.max(w, h); // get max size\n    const imgPadded = img.pad([\n      [0, maxSize - h], // padding y [bottom only]\n      [0, maxSize - w], // padding x [right only]\n      [0, 0],\n    ]);\n\n    xRatio = maxSize / w; // update xRatio\n    yRatio = maxSize / h; // update yRatio\n\n    return tf.image\n      .resizeBilinear(imgPadded, [modelWidth, modelHeight]) // resize frame\n      .div(255.0) // normalize\n      .expandDims(0); // add batch\n  });\n\n  return [input, xRatio, yRatio];\n};\n\n/**\n * Function run inference and do detection from source.\n * @param {HTMLImageElement|HTMLVideoElement} source\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\n * @param {HTMLCanvasElement} canvasRef canvas reference\n * @param {VoidFunction} callback function to run after detection process\n */\nexport const detect = async (source, model, canvasRef, callback = () => {}) => {\n  const [modelWidth, modelHeight] = model.inputShape.slice(1, 3); // get model width and height\n\n  tf.engine().startScope(); // start scoping tf engine\n  const [input, xRatio, yRatio] = preprocess(source, modelWidth, modelHeight); // preprocess image\n\n  const res = model.net.execute(input); // inference model\n  const transRes = res.transpose([0, 2, 1]); // transpose result [b, det, n] => [b, n, det]\n  const boxes = tf.tidy(() => {\n    const w = transRes.slice([0, 0, 2], [-1, -1, 1]); // get width\n    const h = transRes.slice([0, 0, 3], [-1, -1, 1]); // get height\n    const x1 = tf.sub(transRes.slice([0, 0, 0], [-1, -1, 1]), tf.div(w, 2)); // x1\n    const y1 = tf.sub(transRes.slice([0, 0, 1], [-1, -1, 1]), tf.div(h, 2)); // y1\n    return tf\n      .concat(\n        [\n          y1,\n          x1,\n          tf.add(y1, h), //y2\n          tf.add(x1, w), //x2\n        ],\n        2\n      )\n      .squeeze();\n  }); // process boxes [y1, x1, y2, x2]\n\n  const [scores, classes] = tf.tidy(() => {\n    // class scores\n    const rawScores = transRes.slice([0, 0, 4], [-1, -1, numClass]).squeeze(0); // #6 only squeeze axis 0 to handle only 1 class models\n    return [rawScores.max(1), rawScores.argMax(1)];\n  }); // get max scores and classes index\n\n  const nms = await tf.image.nonMaxSuppressionAsync(boxes, scores, 500, 0.45, 0.2); // NMS to filter boxes\n\n  const boxes_data = boxes.gather(nms, 0).dataSync(); // indexing boxes by nms index\n  const scores_data = scores.gather(nms, 0).dataSync(); // indexing scores by nms index\n  const classes_data = classes.gather(nms, 0).dataSync(); // indexing classes by nms index\n\n  renderBoxes(canvasRef, boxes_data, scores_data, classes_data, [xRatio, yRatio]); // render boxes\n  tf.dispose([res, transRes, boxes, scores, classes, nms]); // clear memory\n\n  callback();\n\n  tf.engine().endScope(); // end of scoping\n};\n\n/**\n * Function to detect video from every source.\n * @param {HTMLVideoElement} vidSource video source\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\n * @param {HTMLCanvasElement} canvasRef canvas reference\n */\nexport const detectVideo = (vidSource, model, canvasRef) => {\n  /**\n   * Function to detect every frame from video\n   */\n  const detectFrame = async () => {\n    if (vidSource.videoWidth === 0 && vidSource.srcObject === null) {\n      const ctx = canvasRef.getContext(\"2d\");\n      ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height); // clean canvas\n      return; // handle if source is closed\n    }\n\n    detect(vidSource, model, canvasRef, () => {\n      requestAnimationFrame(detectFrame); // get another frame\n    });\n  };\n\n  detectFrame(); // initialize to detect every frame\n};\n"],"mappings":"AAAA,OAAO,KAAKA,EAAE,MAAM,kBAAkB;AACtC,SAASC,WAAW,QAAQ,aAAa;AACzC,OAAOC,MAAM,MAAM,eAAe;AAElC,MAAMC,QAAQ,GAAGD,MAAM,CAACE,MAAM;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMC,UAAU,GAAGA,CAACC,MAAM,EAAEC,UAAU,EAAEC,WAAW,KAAK;EACtD,IAAIC,MAAM,EAAEC,MAAM,CAAC,CAAC;;EAEpB,MAAMC,KAAK,GAAGX,EAAE,CAACY,IAAI,CAAC,MAAM;IAC1B,MAAMC,GAAG,GAAGb,EAAE,CAACc,OAAO,CAACC,UAAU,CAACT,MAAM,CAAC;;IAEzC;IACA,MAAM,CAACU,CAAC,EAAEC,CAAC,CAAC,GAAGJ,GAAG,CAACK,KAAK,CAACC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACtC,MAAMC,OAAO,GAAGC,IAAI,CAACC,GAAG,CAACL,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC;IAChC,MAAMO,SAAS,GAAGV,GAAG,CAACW,GAAG,CAAC,CACxB,CAAC,CAAC,EAAEJ,OAAO,GAAGJ,CAAC,CAAC;IAAE;IAClB,CAAC,CAAC,EAAEI,OAAO,GAAGH,CAAC,CAAC;IAAE;IAClB,CAAC,CAAC,EAAE,CAAC,CAAC,CACP,CAAC;IAEFR,MAAM,GAAGW,OAAO,GAAGH,CAAC,CAAC,CAAC;IACtBP,MAAM,GAAGU,OAAO,GAAGJ,CAAC,CAAC,CAAC;;IAEtB,OAAOhB,EAAE,CAACyB,KAAK,CACZC,cAAc,CAACH,SAAS,EAAE,CAAChB,UAAU,EAAEC,WAAW,CAAC,CAAC,CAAC;IAAA,CACrDmB,GAAG,CAAC,KAAK,CAAC,CAAC;IAAA,CACXC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;EACpB,CAAC,CAAC;;EAEF,OAAO,CAACjB,KAAK,EAAEF,MAAM,EAAEC,MAAM,CAAC;AAChC,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMmB,MAAM,GAAG,MAAAA,CAAOvB,MAAM,EAAEwB,KAAK,EAAEC,SAAS,EAAEC,QAAQ,GAAGA,CAAA,KAAM,CAAC,CAAC,KAAK;EAC7E,MAAM,CAACzB,UAAU,EAAEC,WAAW,CAAC,GAAGsB,KAAK,CAACG,UAAU,CAACd,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;;EAEhEnB,EAAE,CAACkC,MAAM,CAAC,CAAC,CAACC,UAAU,CAAC,CAAC,CAAC,CAAC;EAC1B,MAAM,CAACxB,KAAK,EAAEF,MAAM,EAAEC,MAAM,CAAC,GAAGL,UAAU,CAACC,MAAM,EAAEC,UAAU,EAAEC,WAAW,CAAC,CAAC,CAAC;;EAE7E,MAAM4B,GAAG,GAAGN,KAAK,CAACO,GAAG,CAACC,OAAO,CAAC3B,KAAK,CAAC,CAAC,CAAC;EACtC,MAAM4B,QAAQ,GAAGH,GAAG,CAACI,SAAS,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;EAC3C,MAAMC,KAAK,GAAGzC,EAAE,CAACY,IAAI,CAAC,MAAM;IAC1B,MAAMK,CAAC,GAAGsB,QAAQ,CAACpB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAClD,MAAMH,CAAC,GAAGuB,QAAQ,CAACpB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAClD,MAAMuB,EAAE,GAAG1C,EAAE,CAAC2C,GAAG,CAACJ,QAAQ,CAACpB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAEnB,EAAE,CAAC2B,GAAG,CAACV,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACzE,MAAM2B,EAAE,GAAG5C,EAAE,CAAC2C,GAAG,CAACJ,QAAQ,CAACpB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAEnB,EAAE,CAAC2B,GAAG,CAACX,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACzE,OAAOhB,EAAE,CACN6C,MAAM,CACL,CACED,EAAE,EACFF,EAAE,EACF1C,EAAE,CAAC8C,GAAG,CAACF,EAAE,EAAE5B,CAAC,CAAC;IAAE;IACfhB,EAAE,CAAC8C,GAAG,CAACJ,EAAE,EAAEzB,CAAC,CAAC,CAAE;IAAA,CAChB,EACD,CACF,CAAC,CACA8B,OAAO,CAAC,CAAC;EACd,CAAC,CAAC,CAAC,CAAC;;EAEJ,MAAM,CAACC,MAAM,EAAEC,OAAO,CAAC,GAAGjD,EAAE,CAACY,IAAI,CAAC,MAAM;IACtC;IACA,MAAMsC,SAAS,GAAGX,QAAQ,CAACpB,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAEhB,QAAQ,CAAC,CAAC,CAAC4C,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5E,OAAO,CAACG,SAAS,CAAC5B,GAAG,CAAC,CAAC,CAAC,EAAE4B,SAAS,CAACC,MAAM,CAAC,CAAC,CAAC,CAAC;EAChD,CAAC,CAAC,CAAC,CAAC;;EAEJ,MAAMC,GAAG,GAAG,MAAMpD,EAAE,CAACyB,KAAK,CAAC4B,sBAAsB,CAACZ,KAAK,EAAEO,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;;EAElF,MAAMM,UAAU,GAAGb,KAAK,CAACc,MAAM,CAACH,GAAG,EAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAC,CAAC;EACpD,MAAMC,WAAW,GAAGT,MAAM,CAACO,MAAM,CAACH,GAAG,EAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAC,CAAC;EACtD,MAAME,YAAY,GAAGT,OAAO,CAACM,MAAM,CAACH,GAAG,EAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAC,CAAC;;EAExDvD,WAAW,CAAC8B,SAAS,EAAEuB,UAAU,EAAEG,WAAW,EAAEC,YAAY,EAAE,CAACjD,MAAM,EAAEC,MAAM,CAAC,CAAC,CAAC,CAAC;EACjFV,EAAE,CAAC2D,OAAO,CAAC,CAACvB,GAAG,EAAEG,QAAQ,EAAEE,KAAK,EAAEO,MAAM,EAAEC,OAAO,EAAEG,GAAG,CAAC,CAAC,CAAC,CAAC;;EAE1DpB,QAAQ,CAAC,CAAC;EAEVhC,EAAE,CAACkC,MAAM,CAAC,CAAC,CAAC0B,QAAQ,CAAC,CAAC,CAAC,CAAC;AAC1B,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,WAAW,GAAGA,CAACC,SAAS,EAAEhC,KAAK,EAAEC,SAAS,KAAK;EAC1D;AACF;AACA;EACE,MAAMgC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAID,SAAS,CAACE,UAAU,KAAK,CAAC,IAAIF,SAAS,CAACG,SAAS,KAAK,IAAI,EAAE;MAC9D,MAAMC,GAAG,GAAGnC,SAAS,CAACoC,UAAU,CAAC,IAAI,CAAC;MACtCD,GAAG,CAACE,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEF,GAAG,CAACG,MAAM,CAACC,KAAK,EAAEJ,GAAG,CAACG,MAAM,CAACE,MAAM,CAAC,CAAC,CAAC;MAC1D,OAAO,CAAC;IACV;;IAEA1C,MAAM,CAACiC,SAAS,EAAEhC,KAAK,EAAEC,SAAS,EAAE,MAAM;MACxCyC,qBAAqB,CAACT,WAAW,CAAC,CAAC,CAAC;IACtC,CAAC,CAAC;EACJ,CAAC;;EAEDA,WAAW,CAAC,CAAC,CAAC,CAAC;AACjB,CAAC"},"metadata":{},"sourceType":"module"}