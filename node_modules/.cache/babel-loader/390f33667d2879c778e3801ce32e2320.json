{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul, broadcast_util, buffer, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { reshape } from './Reshape';\nexport function batchMatMul(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    a,\n    b\n  } = inputs;\n  const {\n    transposeA,\n    transposeB\n  } = attrs;\n  assertNotComplex([a, b], 'matMul');\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n  util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` + `${innerShapeB}) of Tensors with shapes ${a.shape} and ` + `${b.shape} and transposeA=${transposeA}` + ` and transposeB=${transposeB} must match.`);\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({\n    inputs: {\n      x: a\n    },\n    backend,\n    attrs: {\n      shape: a3dShape\n    }\n  });\n  const b3d = reshape({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      shape: b3dShape\n    }\n  });\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n  const a3dValues = backend.data.get(a3d.dataId).values;\n  const b3dValues = backend.data.get(b3d.dataId).values;\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n  const resVals = result.values;\n  const blockSize = backend.blockSize;\n  for (let bi = 0; bi < batchDim; bi++) {\n    const batchIndexA = bi % batchDimA;\n    const batchIndexB = bi % batchDimB;\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      // for when blockSize doesn't evenly divide the input\n      const iBlock = Math.min(i0 + blockSize, leftDim);\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        const jBlock = Math.min(j0 + blockSize, rightDim);\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n              for (let k = k0; k < kBlock; k++) {\n                const aVal =\n                // tslint:disable-next-line: max-line-length\n                a3dValues[batchIndexA * aBatch + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                // tslint:disable-next-line: max-line-length\n                b3dValues[k * bInnerStep + j * bOuterStep + batchIndexB * bBatch];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n  // set correct shape on output.\n  return backend.makeTensorInfo(outShape, result.dtype, result.values);\n}\nexport const batchMatMulConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/BatchMatMul.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,WAAW,EAAuC,cAAc,EAAE,MAAM,EAAwC,IAAI,QAAO,uBAAuB;AAG1J,SAAQ,gBAAgB,QAAO,aAAa;AAE5C,SAAQ,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAU,WAAW,CAAC,IAI3B,EAAA;EACC,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC,CAAC;IAAE;EAAC,CAAC,GAAG,MAAM;EACrB,MAAM;IAAC,UAAU;IAAE;EAAU,CAAC,GAAG,KAAK;EAEtC,gBAAgB,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,CAAC;EAElC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAC5B,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAE5B,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC;EACxE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC;EAExE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC;EACxE,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC;EAExE,MAAM,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EACvC,MAAM,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EAEvC,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC;EAChD,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC;EAEhD,MAAM,iBAAiB,GAAG,cAAc,CAAC,0BAA0B,CAC/D,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;EAC/C,MAAM,QAAQ,GAAG,iBAAiB,CAAC,MAAM,CAAC,CAAC,WAAW,EAAE,WAAW,CAAC,CAAC;EAErE,IAAI,CAAC,MAAM,CACP,WAAW,KAAK,WAAW,EAC3B,MAAM,kCAAkC,WAAW,SAAS,GACxD,GAAG,WAAW,4BAA4B,CAAC,CAAC,KAAK,OAAO,GACxD,GAAG,CAAC,CAAC,KAAK,mBAAmB,UAAU,EAAE,GACzC,mBAAmB,UAAU,cAAc,CAAC;EAEpD,MAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC,GACrC,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC;EACnE,MAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC,GACrC,CAAC,SAAS,EAAE,WAAW,EAAE,WAAW,CAAC;EAEnE;EACA,MAAM,GAAG,GAAG,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAC,CAAC;IAAE,OAAO;IAAE,KAAK,EAAE;MAAC,KAAK,EAAE;IAAQ;EAAC,CAAC,CAAC;EACxE,MAAM,GAAG,GAAG,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAC,CAAC;IAAE,OAAO;IAAE,KAAK,EAAE;MAAC,KAAK,EAAE;IAAQ;EAAC,CAAC,CAAC;EAExE,MAAM,SAAS,GAAG,UAAU,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;EAC1D,MAAM,OAAO,GAAG,UAAU,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;EACxD,MAAM,QAAQ,GAAG,UAAU,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;EACzD,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,SAAS,EAAE,SAAS,CAAC;EAE/C,MAAM,SAAS,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,MAAoB;EACnE,MAAM,SAAS,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,MAAoB;EAEnE,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,KAAK,CAAC;EACjD,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,KAAK,CAAC;EAEjD,MAAM,CAAC,MAAM,EAAE,UAAU,EAAE,UAAU,CAAC,GAAG,UAAU,GAC/C,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,GACjC,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;EACrC,MAAM,CAAC,UAAU,EAAE,UAAU,EAAE,MAAM,CAAC,GAAG,UAAU,GAC/C,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,GACjC,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC;EAErC,MAAM,IAAI,GAAG,OAAO,GAAG,QAAQ;EAC/B,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,QAAQ,EAAE,OAAO,EAAE,QAAQ,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC;EAE/D,MAAM,OAAO,GAAG,MAAM,CAAC,MAAoB;EAC3C,MAAM,SAAS,GAAG,OAAO,CAAC,SAAS;EAEnC,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,EAAE,EAAE,EAAE,EAAE;IACpC,MAAM,WAAW,GAAG,EAAE,GAAG,SAAS;IAClC,MAAM,WAAW,GAAG,EAAE,GAAG,SAAS;IAClC,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,OAAO,EAAE,EAAE,IAAI,SAAS,EAAE;MAC9C;MACA,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,SAAS,EAAE,OAAO,CAAC;MAChD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,EAAE,EAAE,IAAI,SAAS,EAAE;QAC/C,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,SAAS,EAAE,QAAQ,CAAC;QACjD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,SAAS,EAAE,EAAE,IAAI,SAAS,EAAE;UAChD,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,SAAS,EAAE,SAAS,CAAC;UAElD,KAAK,IAAI,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;YAChC,KAAK,IAAI,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;cAChC,IAAI,GAAG,GAAG,GAAG;cAEb,KAAK,IAAI,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;gBAChC,MAAM,IAAI;gBACN;gBACA,SAAS,CAAC,WAAW,GAAG,MAAM,GAAG,CAAC,GAAG,UAAU,GAAG,CAAC,GAAG,UAAU,CAAC;gBACrE,MAAM,IAAI;gBACN;gBACA,SAAS,CAAC,CAAC,GAAG,UAAU,GAAG,CAAC,GAAG,UAAU,GAAG,WAAW,GAAG,MAAM,CAAC;gBACrE,GAAG,IAAI,IAAI,GAAG,IAAI;cACnB;cACD,OAAO,CAAC,EAAE,GAAG,IAAI,IAAI,CAAC,GAAG,QAAQ,GAAG,CAAC,CAAC,CAAC,IAAI,GAAG;YAC/C;UACF;QACF;MACF;IACF;EACF;EAED,OAAO,CAAC,6BAA6B,CAAC,GAAG,CAAC;EAC1C,OAAO,CAAC,6BAA6B,CAAC,GAAG,CAAC;EAE1C;EACA,OAAO,OAAO,CAAC,cAAc,CACzB,QAAQ,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAoB,CAAC;AAC1D;AAEA,OAAO,MAAM,iBAAiB,GAAiB;EAC7C,UAAU,EAAE,WAAW;EACvB,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    const batchIndexA = bi % batchDimA;\n    const batchIndexB = bi % batchDimB;\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      // for when blockSize doesn't evenly divide the input\n      const iBlock = Math.min(i0 + blockSize, leftDim);\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        const jBlock = Math.min(j0 + blockSize, rightDim);\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const aVal =\n                    // tslint:disable-next-line: max-line-length\n                    a3dValues[batchIndexA * aBatch + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    // tslint:disable-next-line: max-line-length\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchIndexB * bBatch];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as unknown as KernelFunc,\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}